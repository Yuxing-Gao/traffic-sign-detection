{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running on new images\n",
    "This notebook will walk you step by step through the process of using a pre-trained model to detect traffic signs in an image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import glob as glob\n",
    "import random\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append('../models/research')  # Replace with the path to TensorFlow Object Detection API\n",
    "sys.path.append('../darkflow')  # Replace with the path to Darkflow\n",
    "\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Object Detection API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL_NAME = 'faster_rcnn_inception_resnet_v2_atrous'\n",
    "# MODEL_NAME = 'faster_rcnn_resnet_101'\n",
    "# MODEL_NAME = 'faster_rcnn_resnet50'\n",
    "MODEL_NAME = 'faster_rcnn_inception_v2'\n",
    "# MODEL_NAME = 'rfcn_resnet101'\n",
    "# MODEL_NAME = 'ssd_inception_v2'\n",
    "# MODEL_NAME = 'ssd_mobilenet_v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to frozen detection graph. This is the actual model that is used for the traffic sign detection.\n",
    "MODEL_PATH = os.path.join('models', MODEL_NAME)\n",
    "PATH_TO_CKPT = os.path.join(MODEL_PATH,'inference_graph/frozen_inference_graph.pb')\n",
    "\n",
    "# List of the strings that is used to add correct label for each box.\n",
    "PATH_TO_LABELS = os.path.join('gtsdb_data', 'gtsdb3_label_map.pbtxt')\n",
    "\n",
    "NUM_CLASSES = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a (frozen) Tensorflow model into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "    od_graph_def = tf.GraphDef()\n",
    "    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading label map\n",
    "Label maps map indices to category names, so that when our convolution network predicts `2`, we know that this corresponds to `mandatory`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/yuxing/my_project/envpy3.6/lib/python3.6/site-packages/object_detection/utils/label_map_util.py:132: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "item {\n",
      "  name: \"prohibitory\"\n",
      "  id: 1\n",
      "}\n",
      "item {\n",
      "  name: \"mandatory\"\n",
      "  id: 2\n",
      "}\n",
      "item {\n",
      "  name: \"danger\"\n",
      "  id: 3\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PATH_TO_LABELS = '/home/yuxing/my_project/traffic-sign-detection/gtsdb_data/gtsdb3_label_map.pbtxt'\n",
    "\n",
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)\n",
    "print(label_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_into_numpy_array(image):\n",
    "    (im_width, im_height) = image.size\n",
    "    return np.array(image.getdata()).reshape((im_height, im_width, 3)).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PATH_TO_TEST_IMAGES_DIR = '/home/yuxing/my_project/traffic-sign-detection/test_images'\n",
    "# for png_image_path in glob.glob(os.path.join(PATH_TO_TEST_IMAGES_DIR, '*.png')):\n",
    "#     with Image.open(png_image_path) as im:\n",
    "#         # Get the image name without extension\n",
    "#         image_name = os.path.splitext(os.path.basename(png_image_path))[0]\n",
    "        \n",
    "#         # Define the path for the jpg image\n",
    "#         jpg_image_path = os.path.join(PATH_TO_TEST_IMAGES_DIR, f\"{image_name}.jpg\")\n",
    "        \n",
    "#         # Save the image in jpg format\n",
    "#         im.convert('RGB').save(jpg_image_path)\n",
    "        \n",
    "#         # Optionally, remove the original png image\n",
    "#         os.remove(png_image_path)\n",
    "\n",
    "TEST_IMAGE_PATHS = glob.glob(os.path.join(PATH_TO_TEST_IMAGES_DIR, '*.jpg'))\n",
    "\n",
    "# Size, in inches, of the output images.\n",
    "IMAGE_SIZE = (20, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "\n",
    "# PATH_TO_TEST_IMAGES_DIR = '/home/yuxing/my_project/traffic-sign-detection/Image_sent4'\n",
    "\n",
    "# # Create a subdirectory named \"images_positive_detection\" if it doesn't exist\n",
    "# detected_dir = os.path.join(PATH_TO_TEST_IMAGES_DIR, \"images_positive_detection\")\n",
    "# if not os.path.exists(detected_dir):\n",
    "#     os.makedirs(detected_dir)\n",
    "\n",
    "# image_counter = 530  # Initialize counter for saved image filenames\n",
    "\n",
    "# with detection_graph.as_default():\n",
    "#     with tf.Session(graph=detection_graph) as sess:\n",
    "#         for idx, image_path in enumerate(TEST_IMAGE_PATHS):\n",
    "#             image = Image.open(image_path)\n",
    "#             image_np = load_image_into_numpy_array(image)\n",
    "#             image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "            \n",
    "#             image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "#             boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "#             scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "#             classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "#             num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "            \n",
    "#             (boxes, scores, classes, num_detections) = sess.run(\n",
    "#                 [boxes, scores, classes, num_detections],\n",
    "#                 feed_dict={image_tensor: image_np_expanded})\n",
    "\n",
    "#             if np.max(scores) > 0.5:\n",
    "#                 # If the image has a positive detection, save the original image\n",
    "#                 output_filename = os.path.join(detected_dir, f\"test_images_{image_counter:03}.jpg\")\n",
    "#                 shutil.copy2(image_path, output_filename)\n",
    "                \n",
    "#                 image_counter += 1  # Increment the counter for the next filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# with detection_graph.as_default():\n",
    "#     with tf.Session(graph=detection_graph) as sess:\n",
    "#         for idx, image_path in enumerate(TEST_IMAGE_PATHS):\n",
    "#             image = Image.open(image_path)\n",
    "#             # the array based representation of the image will be used later in order to prepare the\n",
    "#             # result image with boxes and labels on it.\n",
    "#             image_np = load_image_into_numpy_array(image)\n",
    "#             # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "#             image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "#             image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "#             # Each box represents a part of the image where a particular object was detected.\n",
    "#             boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "#             # Each score represent how level of confidence for each of the objects.\n",
    "#             # Score is shown on the result image, together with the class label.\n",
    "#             scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "#             classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "#             num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "#             # Actual detection.\n",
    "#             (boxes, scores, classes, num_detections) = sess.run(\n",
    "#                 [boxes, scores, classes, num_detections],\n",
    "#                 feed_dict={image_tensor: image_np_expanded})\n",
    "#             # Visualization of the results of a detection.\n",
    "#             vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "#                 image_np,\n",
    "#                 np.squeeze(boxes),\n",
    "#                 np.squeeze(classes).astype(np.int32),\n",
    "#                 np.squeeze(scores),\n",
    "#                 category_index,\n",
    "#                 use_normalized_coordinates=True,\n",
    "#                 line_thickness=6)\n",
    "#             plt.figure(idx, figsize=IMAGE_SIZE)\n",
    "#             plt.axis('off')\n",
    "#             plt.imshow(image_np)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_threshold = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Patch image processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image, ImageEnhance\n",
    "\n",
    "# # Load the image\n",
    "# image1 = Image.open('batch/1.jpg')\n",
    "# image2 = Image.open('batch/2.jpg')\n",
    "\n",
    "# # Initialize the ImageEnhancer objects for brightness and sharpness\n",
    "# enhancer_brightness = ImageEnhance.Brightness(image1)\n",
    "# enhancer_sharpness = ImageEnhance.Sharpness(image1)\n",
    "\n",
    "# # Decrease the brightness and sharpness by 50% and save the image\n",
    "# enhanced_image1 = enhancer_sharpness.enhance(0.5)\n",
    "# enhanced_image1 = enhancer_brightness.enhance(0.5)\n",
    "# enhanced_image1.save('batch/1_modified.jpg')\n",
    "\n",
    "# # Repeat the same process for the second image\n",
    "# enhancer_brightness = ImageEnhance.Brightness(image2)\n",
    "# enhancer_sharpness = ImageEnhance.Sharpness(image2)\n",
    "\n",
    "# # Decrease the brightness and sharpness by 50% and save the image\n",
    "# enhanced_image2 = enhancer_sharpness.enhance(0.5)\n",
    "# enhanced_image2 = enhancer_brightness.enhance(0.5)\n",
    "# enhanced_image2.save('batch/2_modified.jpg')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding two patchs on the detected traffic signs (random positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Perform object detection on the images\n",
    "# total_boxes_processed = 0\n",
    "# total_batches_added = 0\n",
    "# modified_images_list = []\n",
    "\n",
    "# with detection_graph.as_default():\n",
    "#     with tf.Session(graph=detection_graph) as sess:\n",
    "#         for idx, image_path in enumerate(TEST_IMAGE_PATHS):\n",
    "#             image = Image.open(image_path)\n",
    "#             image_np = load_image_into_numpy_array(image)\n",
    "#             image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "#             image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "#             boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "#             scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "#             classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "#             num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "#             (boxes, scores, classes, num_detections) = sess.run(\n",
    "#                 [boxes, scores, classes, num_detections],\n",
    "#                 feed_dict={image_tensor: image_np_expanded})\n",
    "\n",
    "#             # Get the number of valid detected boxes and print their indices\n",
    "#             valid_boxes = boxes[0, :int(num_detections[0])]\n",
    "#             valid_scores = scores[0, :int(num_detections[0])]\n",
    "#             num_valid_boxes = sum(valid_scores > confidence_threshold)  # Count boxes with confidence above threshold\n",
    "#             total_boxes_processed += num_valid_boxes\n",
    "#             print(\"Image\", idx, \"Detected Boxes:\", num_valid_boxes)\n",
    "#             print([len(box) for box in valid_boxes])\n",
    "\n",
    "#             # Add batch image to the boxes and store the modified image\n",
    "#             batch_image_paths = ['batch/1_modified.jpg', 'batch/2_modified.jpg']  # Replace with the paths to your batch images\n",
    "#             image_np_with_batch = add_patch_to_boxes(image_np.copy(), valid_boxes[:num_valid_boxes], batch_image_paths)\n",
    "\n",
    "#             # Count the number of batches added in this image\n",
    "#             num_batches_added = num_valid_boxes\n",
    "#             total_batches_added += num_batches_added\n",
    "#             print(\"Batches added in this image:\", num_batches_added)\n",
    "\n",
    "#             # Store the modified image without showing bounding boxes\n",
    "#             modified_images_list.append(image_np_with_batch)\n",
    "\n",
    "# # Display the modified images without showing bounding boxes\n",
    "# for idx, image_np_with_boxes in enumerate(modified_images_list):\n",
    "#     plt.figure(figsize=IMAGE_SIZE)\n",
    "#     plt.axis('off')\n",
    "#     plt.imshow(image_np_with_boxes)\n",
    "#     # plt.savefig(f'image_with_batches_{idx+1}.png')  # Save the image with a unique name\n",
    "#     plt.show()\n",
    "\n",
    "# # Print the total number of boxes processed and total batches added\n",
    "# print(\"Total boxes processed:\", total_boxes_processed)\n",
    "# print(\"Total batches added:\", total_batches_added)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def central_coordinates(ymin, xmin, ymax, xmax, box_height, box_width, image_np):\n",
    "    center_y = (ymin + ymax) * 0.5 * image_np.shape[0]\n",
    "    center_x = (xmin + xmax) * 0.5 * image_np.shape[1]\n",
    "    new_height = box_height * 0.7\n",
    "    new_width = box_width * 0.7\n",
    "    new_ymin = max(0, center_y - new_height * 0.5)\n",
    "    new_xmin = max(0, center_x - new_width * 0.5)\n",
    "    new_ymax = min(image_np.shape[0], center_y + new_height * 0.5)\n",
    "    new_xmax = min(image_np.shape[1], center_x + new_width * 0.5)\n",
    "    return new_ymin, new_xmin, new_ymax, new_xmax\n",
    "\n",
    "def generate_non_overlapping_positions(ymin, xmin, ymax, xmax, batch_height, batch_width, aspect_ratio):\n",
    "    if aspect_ratio > 1:  # Box is taller than it is wide\n",
    "        half_height = (ymax + ymin) // 2\n",
    "        y_start_1 = ymin\n",
    "        y_end_1 = max(ymin, half_height - batch_height)\n",
    "        y_start_2 = half_height\n",
    "        y_end_2 = max(half_height, ymax - batch_height)\n",
    "\n",
    "        if y_end_1 <= y_start_1 or y_end_2 <= y_start_2:  # not enough space\n",
    "            return None, None\n",
    "\n",
    "        first_y = random.randint(y_start_1, y_end_1)\n",
    "        second_y = random.randint(y_start_2, y_end_2)\n",
    "        x = random.randint(xmin, xmax - batch_width)\n",
    "        return (first_y, x), (second_y, x)\n",
    "\n",
    "    else:  # Box is wider than it is tall\n",
    "        half_width = (xmax + xmin) // 2\n",
    "        x_start_1 = xmin\n",
    "        x_end_1 = max(xmin, half_width - batch_width)\n",
    "        x_start_2 = half_width\n",
    "        x_end_2 = max(half_width, xmax - batch_width)\n",
    "\n",
    "        if x_end_1 <= x_start_1 or x_end_2 <= x_start_2:  # not enough space\n",
    "            return None, None\n",
    "\n",
    "        first_x = random.randint(x_start_1, x_end_1)\n",
    "        second_x = random.randint(x_start_2, x_end_2)\n",
    "        y = random.randint(ymin, ymax - batch_height)\n",
    "        return (y, first_x), (y, second_x)\n",
    "\n",
    "def add_patch_to_boxes(image_np, boxes, scores, batch_image_paths, confidence_threshold=0.5):\n",
    "    \"\"\"Add the batch images to the bounding boxes.\"\"\"\n",
    "    for idx, box in enumerate(boxes):\n",
    "        if scores[idx] < confidence_threshold:\n",
    "            continue  # Skip boxes with low confidence\n",
    "        ymin, xmin, ymax, xmax = box\n",
    "        box_height = int((ymax - ymin) * image_np.shape[0])\n",
    "        box_width = int((xmax - xmin) * image_np.shape[1])\n",
    "\n",
    "        new_ymin, new_xmin, new_ymax, new_xmax = central_coordinates(ymin, xmin, ymax, xmax, box_height, box_width, image_np)\n",
    "\n",
    "        batch_image_height = box_height // 4\n",
    "        batch_image_width = box_width // 4\n",
    "        aspect_ratio = box_height / box_width\n",
    "\n",
    "        positions = generate_non_overlapping_positions(\n",
    "            int(new_ymin), int(new_xmin), int(new_ymax), int(new_xmax),\n",
    "            batch_image_height, batch_image_width, aspect_ratio\n",
    "        )\n",
    "\n",
    "        if not positions[0] or not positions[1]:  # Not enough space for the batches\n",
    "            continue  # Skip adding batches for this box\n",
    "\n",
    "        (y1, x1), (y2, x2) = positions\n",
    "\n",
    "        for batch_idx, batch_image_path in enumerate(batch_image_paths):\n",
    "            batch_image = Image.open(batch_image_path)\n",
    "            batch_image_resized = batch_image.resize((batch_image_width, batch_image_height))\n",
    "            batch_np = np.array(batch_image_resized)\n",
    "            if batch_idx == 0:\n",
    "                image_np[y1:y1 + batch_np.shape[0], x1:x1 + batch_np.shape[1]] = batch_np\n",
    "            else:\n",
    "                image_np[y2:y2 + batch_np.shape[0], x2:x2 + batch_np.shape[1]] = batch_np\n",
    "\n",
    "    return image_np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# START_IDX = 1  # Starting index (inclusive)\n",
    "# END_IDX = 600  # Ending index (inclusive)\n",
    "\n",
    "# PATH_TO_TEST_IMAGES_DIR = '/home/yuxing/my_project/traffic-sign-detection/test_images'\n",
    "# TEST_IMAGE_PATHS = [os.path.join(PATH_TO_TEST_IMAGES_DIR, f'test_image_{i:03}.jpg') for i in range(START_IDX, END_IDX+1)]\n",
    "# confidence_threshold = 0.5\n",
    "# IMAGE_SIZE = (20, 20)\n",
    "# results = {}  # A dictionary to save detection results for all images\n",
    "\n",
    "# def run_detection_and_save(image_np, image_path, idx, save_dir, prefix, save_bbox=True):\n",
    "#     with detection_graph.as_default():\n",
    "#         with tf.Session(graph=detection_graph) as sess:\n",
    "#             image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "#             image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "#             boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "#             scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "#             classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "            \n",
    "#             (output_boxes, output_scores, output_classes) = sess.run(\n",
    "#                 [boxes, scores, classes],\n",
    "#                 feed_dict={image_tensor: image_np_expanded})\n",
    "\n",
    "#             # Diagnostic Print Statements\n",
    "#             # print(\"Output boxes shape:\", output_boxes.shape)\n",
    "#             # print(\"Output classes shape:\", output_classes.shape)\n",
    "#             # print(\"Output scores shape:\", output_scores.shape)\n",
    "\n",
    "#             squeezed_boxes = np.squeeze(output_boxes)\n",
    "#             squeezed_classes = np.squeeze(output_classes)\n",
    "#             squeezed_scores = np.squeeze(output_scores)\n",
    "\n",
    "#             # Further Diagnostic Print Statements\n",
    "#             # print(\"Squeezed boxes shape:\", squeezed_boxes.shape)\n",
    "#             # print(\"Squeezed classes shape:\", squeezed_classes.shape)\n",
    "#             # print(\"Squeezed scores shape:\", squeezed_scores.shape)\n",
    "\n",
    "#             # print(\"Unique classes before conversion:\", np.unique(squeezed_classes))\n",
    "#             squeezed_classes = squeezed_classes.astype(np.int32)\n",
    "\n",
    "#             # Save the results\n",
    "#             results[image_path] = {\"boxes\": output_boxes, \"scores\": output_scores, \"classes\": output_classes}\n",
    "\n",
    "#             # If need to save images with bounding boxes\n",
    "#             if save_bbox:\n",
    "#                 vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "#                     image_np,\n",
    "#                     squeezed_boxes,\n",
    "#                     squeezed_classes,\n",
    "#                     squeezed_scores,\n",
    "#                     category_index,\n",
    "#                     use_normalized_coordinates=True,\n",
    "#                     line_thickness=6)\n",
    "\n",
    "#             output_filename = os.path.join(save_dir, f\"{prefix}_{idx+1:03}.jpg\")\n",
    "#             Image.fromarray(image_np).save(output_filename)\n",
    "\n",
    "# # Step 2: Detect on original images and save the results with bounding boxes\n",
    "# for idx, image_path in enumerate(TEST_IMAGE_PATHS):\n",
    "#     image = Image.open(image_path)\n",
    "#     image_np = np.array(image)\n",
    "#     run_detection_and_save(image_np, image_path, idx, \"test_images_box\", \"test_image_box\")\n",
    "\n",
    "# # Step 1 and 3: Add patches and save without bounding boxes\n",
    "# patch_image_save_paths = []  # List to store paths of saved patched images\n",
    "# patch_image_paths = ['/home/yuxing/my_project/traffic-sign-detection/batch/1_modified.jpg',\n",
    "#                      '/home/yuxing/my_project/traffic-sign-detection/batch/2_modified.jpg']\n",
    "\n",
    "# for idx, image_path in enumerate(TEST_IMAGE_PATHS):\n",
    "#     image = Image.open(image_path)\n",
    "#     image_np = np.array(image)\n",
    "    \n",
    "#     squeezed_boxes = results[image_path][\"boxes\"].squeeze()  \n",
    "#     squeezed_scores = results[image_path][\"scores\"].squeeze()  # Get the squeezed scores\n",
    "    \n",
    "#     image_np_with_patch = add_patch_to_boxes(image_np, squeezed_boxes, squeezed_scores, patch_image_paths)\n",
    "    \n",
    "    \n",
    "#     output_filename = os.path.join(\"patch_images\", f\"patch_image_{idx+1:03}.jpg\")\n",
    "#     Image.fromarray(image_np_with_patch).save(output_filename)\n",
    "    \n",
    "#     patch_image_save_paths.append(output_filename)  # Append saved path to list\n",
    "\n",
    "# # Step 4: Detect on patched images and save results with bounding boxes\n",
    "# for idx, image_path in enumerate(patch_image_save_paths):  # Using the saved paths list\n",
    "#     image = Image.open(image_path)\n",
    "#     image_np = np.array(image)\n",
    "#     run_detection_and_save(image_np, image_path, idx, \"patch_images_box\", \"patch_image_box\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import pickle\n",
    "\n",
    "# with open('results.pkl', 'wb') as f:\n",
    "#     pickle.dump(results, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indices with changed classes: [2, 4, 7, 15, 18, 19, 22, 24, 27, 28, 30, 31, 33, 36, 40, 51, 56, 59, 60, 62, 63, 67, 74, 78, 83, 91, 92, 93, 97, 99, 102, 103, 104, 107, 111, 113, 114, 115, 116, 117, 120, 121, 123, 124, 125, 126, 129, 131, 134, 135, 136, 137, 143, 145, 147, 152, 155, 162, 167, 168, 169, 176, 181, 182, 184, 187, 191, 196, 198, 202, 203, 206, 218, 219, 220, 227, 229, 230, 234, 235, 236, 237, 238, 241, 242, 246, 247, 249, 252, 253, 256, 268, 271, 272, 275, 276, 277, 278, 280, 282, 285, 286, 288, 289, 290, 293, 295, 299, 300, 305, 307, 312, 315, 318, 320, 321, 324, 326, 331, 337, 338, 342, 346, 347, 350, 352, 355, 358, 359, 365, 366, 367, 369, 371, 376, 384, 393, 395, 397, 398, 401, 403, 404, 405, 408, 409, 410, 411, 412, 414, 415, 416, 419, 425, 427, 428, 433, 434, 439, 441, 449, 451, 455, 457, 459, 460, 463, 468, 473, 474, 476, 477, 478, 479, 483, 486, 487, 488, 489, 490, 493, 499, 502, 504, 509, 512, 513, 515, 520, 521, 524, 525]\n",
      "indices with changed confidence scores: [9, 76, 79, 141, 166, 175, 180, 212, 243, 254, 279, 297, 305, 306, 310, 325, 334, 337, 378, 388, 401, 402, 456, 474, 481, 484, 510, 520, 528]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('results.pkl', 'rb') as file:\n",
    "    results = pickle.load(file)\n",
    "\n",
    "def iou(box1, box2):\n",
    "    '''Computes the Intersection over Union (IoU) between two boxes.\n",
    "    Each box is defined by its top-left and bottom-right corners: [y1, x1, y2, x2].\n",
    "    '''\n",
    "    y1_max = max(box1[0], box2[0])\n",
    "    x1_max = max(box1[1], box2[1])\n",
    "    y2_min = min(box1[2], box2[2])\n",
    "    x2_min = min(box1[3], box2[3])\n",
    "    \n",
    "    inter_area = max(0, y2_min - y1_max) * max(0, x2_min - x1_max)\n",
    "    \n",
    "    box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "    box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "    \n",
    "    union_area = box1_area + box2_area - inter_area\n",
    "    \n",
    "    return inter_area / union_area\n",
    "\n",
    "test_image_dir = '/home/yuxing/my_project/traffic-sign-detection/test_images/'\n",
    "patch_image_dir = 'patch_images/'\n",
    "\n",
    "changed_classes_indices = []\n",
    "changed_confidence_indices = []\n",
    "\n",
    "# 1. Filtering based on confidence score\n",
    "for image_path, data in results.items():\n",
    "    valid_indices = data['scores'] > 0.5\n",
    "    results[image_path]['boxes'] = data['boxes'][valid_indices]\n",
    "    results[image_path]['scores'] = data['scores'][valid_indices]\n",
    "    results[image_path]['classes'] = data['classes'][valid_indices]\n",
    "\n",
    "\n",
    "threshold_iou = 0.7  # Threshold to consider boxes as overlapping\n",
    "\n",
    "for i in range(1, 530):\n",
    "    test_image_path = os.path.join(test_image_dir, f'test_image_{i:03}.jpg')\n",
    "    patch_image_path = os.path.join(patch_image_dir, f'patch_image_{i:03}.jpg')\n",
    "\n",
    "    test_results = results.get(test_image_path, {})\n",
    "    patch_results = results.get(patch_image_path, {})\n",
    "\n",
    "    test_boxes = test_results.get('boxes', [])\n",
    "    patch_boxes = patch_results.get('boxes', [])\n",
    "    \n",
    "    # If the number of detections is different, add to changed classes\n",
    "    if len(test_boxes) != len(patch_boxes):\n",
    "        changed_classes_indices.append(i)\n",
    "    else:\n",
    "        # Iterate over each box in test_results and find its best match in patch_results\n",
    "        for idx, test_box in enumerate(test_boxes):\n",
    "            best_iou = -1\n",
    "            best_idx = -1\n",
    "            for jdx, patch_box in enumerate(patch_boxes):\n",
    "                current_iou = iou(test_box, patch_box)\n",
    "                if current_iou > best_iou:\n",
    "                    best_iou = current_iou\n",
    "                    best_idx = jdx\n",
    "        \n",
    "            # If we have found a matching box in patch_results with sufficient overlap\n",
    "            if best_iou > threshold_iou:\n",
    "                if test_results['classes'][idx] != patch_results['classes'][best_idx]:\n",
    "                    changed_classes_indices.append(i)\n",
    "                score_diff = np.abs(test_results['scores'][idx] - patch_results['scores'][best_idx])\n",
    "                if score_diff > 0.2:\n",
    "                    changed_confidence_indices.append(i)\n",
    "\n",
    "    # # Print samples for first 3 indices\n",
    "    # if i <= 20:\n",
    "    #     print(f\"Results for index {i}\")\n",
    "    #     print(f\"Test Image Results: {test_results}\")\n",
    "    #     print(f\"Patch Image Results: {patch_results}\")\n",
    "    #     print(\"-------------------------\")\n",
    "\n",
    "\n",
    "\n",
    "print(f\"indices with changed classes: {changed_classes_indices}\")\n",
    "print(f\"indices with changed confidence scores: {changed_confidence_indices}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of images with changed classes: 192\n",
      "number of images with changed confidence: 29\n"
     ]
    }
   ],
   "source": [
    "print(f\"number of images with changed classes: {len(changed_classes_indices)}\")\n",
    "print(f\"number of images with changed confidence: {len(changed_confidence_indices)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
