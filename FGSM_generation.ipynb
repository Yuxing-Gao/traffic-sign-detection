{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running on new images\n",
    "This notebook will walk you step by step through the process of using a pre-trained model to detect traffic signs in an image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import glob as glob\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append('../models/research')  # Replace with the path to TensorFlow Object Detection API\n",
    "sys.path.append('../darkflow')  # Replace with the path to Darkflow\n",
    "\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Object Detection API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL_NAME = 'faster_rcnn_inception_resnet_v2_atrous'\n",
    "# MODEL_NAME = 'faster_rcnn_resnet_101'\n",
    "# MODEL_NAME = 'faster_rcnn_resnet50'\n",
    "MODEL_NAME = 'faster_rcnn_inception_v2'\n",
    "# MODEL_NAME = 'rfcn_resnet101'\n",
    "# MODEL_NAME = 'ssd_inception_v2'\n",
    "# MODEL_NAME = 'ssd_mobilenet_v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to frozen detection graph. This is the actual model that is used for the traffic sign detection.\n",
    "MODEL_PATH = os.path.join('models', MODEL_NAME)\n",
    "PATH_TO_CKPT = os.path.join(MODEL_PATH,'inference_graph/frozen_inference_graph.pb')\n",
    "\n",
    "# List of the strings that is used to add correct label for each box.\n",
    "PATH_TO_LABELS = os.path.join('gtsdb_data', 'gtsdb3_label_map.pbtxt')\n",
    "\n",
    "NUM_CLASSES = 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a (frozen) Tensorflow model into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "    od_graph_def = tf.GraphDef()\n",
    "    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading label map\n",
    "Label maps map indices to category names, so that when our convolution network predicts `2`, we know that this corresponds to `mandatory`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_LABELS = '/home/yuxing/my_project/traffic-sign-detection/gtsdb_data/gtsdb3_label_map.pbtxt'\n",
    "\n",
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)\n",
    "print(label_map)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_into_numpy_array(image):\n",
    "    (im_width, im_height) = image.size\n",
    "    return np.array(image.getdata()).reshape((im_height, im_width, 3)).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PATH_TO_TEST_IMAGES_DIR = '/home/yuxing/my_project/traffic-sign-detection/test_images'\n",
    "\n",
    "TEST_IMAGE_PATHS = glob.glob(os.path.join(PATH_TO_TEST_IMAGES_DIR, '*.jpg'))\n",
    "\n",
    "# Size, in inches, of the output images.\n",
    "IMAGE_SIZE = (20, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_detection_results = {}\n",
    "\n",
    "with detection_graph.as_default():\n",
    "    with tf.Session(graph=detection_graph) as sess:\n",
    "        for idx, image_path in enumerate(TEST_IMAGE_PATHS):\n",
    "            image = Image.open(image_path)\n",
    "            # the array based representation of the image will be used later in order to prepare the\n",
    "            # result image with boxes and labels on it.\n",
    "            image_np = load_image_into_numpy_array(image)\n",
    "            # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "            image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "            print(type(image_np_expanded))\n",
    "            image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "            # Each box represents a part of the image where a particular object was detected.\n",
    "            boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "            # Each score represent how level of confidence for each of the objects.\n",
    "            # Score is shown on the result image, together with the class label.\n",
    "            scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "            classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "            num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "            # Actual detection.\n",
    "            (boxes, scores, classes, num_detections) = sess.run(\n",
    "                [boxes, scores, classes, num_detections],\n",
    "                feed_dict={image_tensor: image_np_expanded})\n",
    "            \n",
    "            # Save the detection results for this image\n",
    "            saved_detection_results[image_path] = {\n",
    "                'boxes': boxes,\n",
    "                'scores': scores,\n",
    "                'classes': classes,\n",
    "                'num_detections': num_detections}\n",
    "\n",
    "            vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "                image_np,\n",
    "                np.squeeze(boxes),\n",
    "                np.squeeze(classes).astype(np.int32),\n",
    "                np.squeeze(scores),\n",
    "                category_index,\n",
    "                use_normalized_coordinates=True,\n",
    "                line_thickness=6)\n",
    "            plt.figure(idx, figsize=IMAGE_SIZE)\n",
    "            plt.axis('off')\n",
    "            plt.imshow(image_np)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def perform_inference(sess, image_tensor, image_np_expanded, boxes, scores, classes, num_detections):\n",
    "    print(f\"Type of image_np_expanded: {type(image_np_expanded)}\")\n",
    "    print(f\"Shape of image_np_expanded: {image_np_expanded.shape if isinstance(image_np_expanded, np.ndarray) else tf.shape(image_np_expanded)}\")\n",
    "    if tf.is_tensor(image_np_expanded):\n",
    "        image_np_expanded = sess.run(image_np_expanded)\n",
    "    return sess.run([boxes, scores, classes, num_detections], \n",
    "                    feed_dict={image_tensor: image_np_expanded})\n",
    "\n",
    "\n",
    "def create_adversarial_pattern(input_image, input_label, sess):\n",
    "    print(f\"Type of input_image: {type(input_image)}\")\n",
    "    print(f\"Shape of input_image: {input_image.shape if isinstance(input_image, np.ndarray) else tf.shape(input_image)}\")\n",
    "    print(f\"Type of input_label: {type(input_label)}\")\n",
    "    if not tf.is_tensor(input_image):\n",
    "        input_image = tf.convert_to_tensor(input_image.astype(np.float32))\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(input_image)\n",
    "        prediction = perform_inference(sess, image_tensor, input_image, boxes, scores, classes, num_detections)\n",
    "        loss = loss_object(input_label, prediction[1]) \n",
    "    \n",
    "    gradient = tape.gradient(loss, input_image)\n",
    "    signed_grad = tf.sign(gradient)\n",
    "    return signed_grad\n",
    "\n",
    "\n",
    "\n",
    "loss_object = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "with detection_graph.as_default():\n",
    "    with tf.Session(graph=detection_graph) as sess:\n",
    "        for idx, image_path in enumerate(TEST_IMAGE_PATHS):\n",
    "            # Get the saved results\n",
    "            boxes = saved_detection_results[image_path]['boxes']\n",
    "            scores = saved_detection_results[image_path]['scores']\n",
    "            classes = saved_detection_results[image_path]['classes']\n",
    "            \n",
    "            # Find the detection with the highest score\n",
    "            max_score_idx = np.argmax(scores)\n",
    "            target_class = int(classes[0, max_score_idx])\n",
    "            \n",
    "            # Create one-hot label for the class\n",
    "            label = tf.one_hot(target_class, NUM_CLASSES)\n",
    "            label = tf.reshape(label, (1, NUM_CLASSES))\n",
    "            \n",
    "            # Prepare the image\n",
    "            image = Image.open(image_path)\n",
    "            image_np = np.array(image).astype(np.uint8)\n",
    "            image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "            input_image = tf.convert_to_tensor(image_np_expanded.astype(np.float32))\n",
    "            \n",
    "            \n",
    "            # Generate the adversarial example\n",
    "            print(f\"Type of input_image before calling create_adversarial_pattern: {type(input_image)}\")\n",
    "            print(f\"Shape of input_image before calling create_adversarial_pattern: {input_image.shape if isinstance(input_image, np.ndarray) else tf.shape(input_image)}\")         \n",
    "            perturbations = create_adversarial_pattern(input_image, label, sess)\n",
    "            \n",
    "            # Create the adversarial image\n",
    "            eps = 0.1\n",
    "            adv_x = image_np + eps * perturbations.numpy()\n",
    "            adv_x = np.clip(adv_x, 0, 255).astype(np.uint8)\n",
    "            \n",
    "            # Run inference on the adversarial image\n",
    "            (adv_boxes, adv_scores, adv_classes, adv_num_detections) = sess.run(\n",
    "                [boxes, scores, classes, num_detections],\n",
    "                feed_dict={image_tensor: np.expand_dims(adv_x, axis=0)})\n",
    "            \n",
    "            \n",
    "            vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "                adv_x,\n",
    "                np.squeeze(adv_boxes),\n",
    "                np.squeeze(adv_classes).astype(np.int32),\n",
    "                np.squeeze(adv_scores),\n",
    "                category_index,\n",
    "                use_normalized_coordinates=True,\n",
    "                line_thickness=6)\n",
    "            \n",
    "            plt.figure(idx, figsize=IMAGE_SIZE)\n",
    "            plt.axis('off')\n",
    "            plt.imshow(adv_x)\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for op in detection_graph.get_operations():\n",
    "    if 'label' in op.name.lower():\n",
    "        print(op.name)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
