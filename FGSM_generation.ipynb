{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running on new images\n",
    "This notebook will walk you step by step through the process of using a pre-trained model to detect traffic signs in an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "# tf.enable_eager_execution()\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "# matplotlib.use('TkAgg')  # Use TkAgg to show images\n",
    "\n",
    "# from PIL import Image\n",
    "import glob as glob\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import sys\n",
    "import cv2\n",
    "\n",
    "%matplotlib inline\n",
    "# tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sys.path.append('../models/research')  # Replace with the path to TensorFlow Object Detection API\n",
    "sys.path.append('../darkflow')  # Replace with the path to Darkflow\n",
    "\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Object Detection API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL_NAME = 'faster_rcnn_inception_resnet_v2_atrous'\n",
    "# MODEL_NAME = 'faster_rcnn_resnet_101'\n",
    "# MODEL_NAME = 'faster_rcnn_resnet50'\n",
    "MODEL_NAME = 'faster_rcnn_inception_v2'\n",
    "# MODEL_NAME = 'rfcn_resnet101'\n",
    "# MODEL_NAME = 'ssd_inception_v2'\n",
    "# MODEL_NAME = 'ssd_mobilenet_v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to frozen detection graph. This is the actual model that is used for the traffic sign detection.\n",
    "MODEL_PATH = os.path.join('models', MODEL_NAME)\n",
    "PATH_TO_CKPT = os.path.join(MODEL_PATH,'inference_graph/frozen_inference_graph.pb')\n",
    "\n",
    "# List of the strings that is used to add correct label for each box.\n",
    "PATH_TO_LABELS = os.path.join('gtsdb_data', 'gtsdb3_label_map.pbtxt')\n",
    "\n",
    "NUM_CLASSES = 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a (frozen) Tensorflow model into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "    od_graph_def = tf.GraphDef()\n",
    "    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading label map\n",
    "Label maps map indices to category names, so that when our convolution network predicts `2`, we know that this corresponds to `mandatory`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_LABELS = r'C:\\Yuxing\\traffic-sign-detection-master\\gtsdb_data\\gtsdb_label_map.pbtxt'\n",
    "\n",
    "# label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "# categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "# category_index = label_map_util.create_category_index(categories)\n",
    "\n",
    "# Directly reading the file for troubleshooting\n",
    "try:\n",
    "    with open(PATH_TO_LABELS, 'rb') as f:\n",
    "        print(\"Direct read:\", f.read())\n",
    "except Exception as e:\n",
    "    print(\"File read error:\", str(e))\n",
    "\n",
    "# Your existing code\n",
    "print('1')\n",
    "try:\n",
    "    label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "except Exception as e:\n",
    "    print(\"Error during label map load:\", str(e))\n",
    "print('2')\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "print('3')\n",
    "category_index = label_map_util.create_category_index(categories)\n",
    "print(label_map)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_into_numpy_array(image):\n",
    "    (im_width, im_height) = image.size\n",
    "    #return np.array(image.getdata()).reshape((im_height, im_width, 3)).astype(np.uint8)\n",
    "    return np.array(image.getdata()).reshape((im_height, im_width, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PATH_TO_TEST_IMAGES_DIR = 'test_images'\n",
    "\n",
    "TEST_IMAGE_PATHS = glob.glob(os.path.join(PATH_TO_TEST_IMAGES_DIR, '*.jpg'))\n",
    "\n",
    "# Size, in inches, of the output images.\n",
    "IMAGE_SIZE = (20, 20)\n",
    "\n",
    "SAVE_DIR = '/test_images_detection'\n",
    "\n",
    "if not os.path.exists(SAVE_DIR):\n",
    "    os.makedirs(SAVE_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to print detections\n",
    "def print_detections(sess, image_np_expanded, detection_graph, image_name, confidence_threshold=0.3):\n",
    "    # Get the tensors for detection\n",
    "    image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "    detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "    detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "    detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "\n",
    "    # Run the session to get the detection boxes, scores, and classes\n",
    "    (boxes, scores, classes) = sess.run(\n",
    "        [detection_boxes, detection_scores, detection_classes],\n",
    "        feed_dict={image_tensor: image_np_expanded}\n",
    "    )\n",
    "\n",
    "    # Filter out the results with confidence scores less than the threshold\n",
    "    filter_indices = np.where(scores[0] >= confidence_threshold)[0]\n",
    "\n",
    "    # Apply the filter to boxes, scores and classes\n",
    "    filtered_boxes = boxes[0][filter_indices]\n",
    "    filtered_scores = scores[0][filter_indices]\n",
    "    filtered_classes = classes[0][filter_indices]\n",
    "\n",
    "    # Print the image name along with other detection results\n",
    "    print(f\"Image Name: {image_name}\")\n",
    "    print(\"Filtered Detection Boxes:\", filtered_boxes)\n",
    "    print(\"Filtered Detection Scores:\", filtered_scores)\n",
    "    print(\"Filtered Detection Classes:\", filtered_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "saved_detection_results = {}\n",
    "\n",
    "# Run inference and visualization\n",
    "with detection_graph.as_default():\n",
    "    with tf.Session(graph=detection_graph) as sess:\n",
    "        for idx, image_path in enumerate(TEST_IMAGE_PATHS):\n",
    "            image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "            boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "            scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "            classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "            num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "\n",
    "            image_data = tf.read_file(image_path)\n",
    "            image_decoded = tf.image.decode_image(image_data)\n",
    "            image_np = sess.run(image_decoded)\n",
    "            image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "\n",
    "            (boxes, scores, classes, num_detections) = sess.run(\n",
    "                [boxes, scores, classes, num_detections],\n",
    "                feed_dict={image_tensor: image_np_expanded})\n",
    "\n",
    "            saved_detection_results[image_path] = {\n",
    "                'boxes': boxes,\n",
    "                'scores': scores,\n",
    "                'classes': classes,\n",
    "                'num_detections': num_detections\n",
    "            }\n",
    "\n",
    "\n",
    "            # Get image name and create a new name\n",
    "            image_name = os.path.basename(image_path)\n",
    "            save_path = os.path.join(SAVE_DIR, f'detection_{image_name}')\n",
    "\n",
    "\n",
    "            # Print and visualize detection results on adversarial image\n",
    "            print_detections(sess, image_np_expanded, detection_graph, image_name)\n",
    "\n",
    "            # Visualize and save detection results on the image\n",
    "            vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "                image_np,\n",
    "                np.squeeze(boxes),\n",
    "                np.squeeze(classes).astype(np.int32),\n",
    "                np.squeeze(scores),\n",
    "                category_index,\n",
    "                use_normalized_coordinates=True,\n",
    "                line_thickness=6)\n",
    "            \n",
    "            # Using matplotlib to save the image\n",
    "            plt.figure(figsize=IMAGE_SIZE)\n",
    "            plt.imshow(image_np)\n",
    "            plt.axis('off')\n",
    "            plt.savefig(save_path, bbox_inches='tight', pad_inches=0)\n",
    "            # plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm 1: Adversarial pattern generation on downsampled image, using the gradient with saturator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuning parameters\n",
    "FACTOR = 0.2\n",
    "H = 5\n",
    "NUM_SAMPLES = 500\n",
    "NUM_ITERATIONS = 40\n",
    "EPS = 400000\n",
    "SAT = 50  # Saturation\n",
    "\n",
    "SAVE_DIR = 'saved_images_1'\n",
    "if not os.path.exists(SAVE_DIR):\n",
    "    os.makedirs(SAVE_DIR)\n",
    "\n",
    "def downsample(image, factor=FACTOR):\n",
    "    return cv2.resize(image, None, fx=factor, fy=factor, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "def upsample(image, original_shape):\n",
    "    return cv2.resize(image, (original_shape[1], original_shape[0]), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "\n",
    "def compute_loss(sess, image_np_expanded, detection_graph):\n",
    "    image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "    scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "    classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "    \n",
    "    (scores, classes) = sess.run([scores, classes], feed_dict={image_tensor: image_np_expanded})\n",
    "    max_score_index = np.argmax(scores)\n",
    "    score = scores[0][max_score_index]\n",
    "    approx_logits = np.log(score / (1 - score))\n",
    "    return approx_logits\n",
    "\n",
    "def approximate_gradient(sess, image_np_expanded, detection_graph, h=H, num_samples=NUM_SAMPLES):\n",
    "    original_loss = compute_loss(sess, image_np_expanded, detection_graph)\n",
    "    grad_approx = np.zeros_like(image_np_expanded).astype(np.float32)\n",
    "    \n",
    "    total_pixels = np.prod(image_np_expanded.shape)\n",
    "    \n",
    "    # Randomly selecting pixel indices from the entire image\n",
    "    indices = np.random.choice(total_pixels, num_samples, replace=False)\n",
    "        \n",
    "    for flat_idx in indices:\n",
    "        idx = np.unravel_index(flat_idx, image_np_expanded.shape)\n",
    "        perturb = np.zeros_like(image_np_expanded)\n",
    "        perturb[idx] = h\n",
    "        perturbed_image = image_np_expanded + perturb\n",
    "        perturbed_loss = compute_loss(sess, perturbed_image, detection_graph)\n",
    "        grad_approx[idx] = (perturbed_loss - original_loss) / h #  + random.uniform(-10e7, 10e7)\n",
    "        \n",
    "    return grad_approx\n",
    "\n",
    "# Main execution\n",
    "with detection_graph.as_default():\n",
    "    with tf.Session(graph=detection_graph) as sess:\n",
    "        image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "        boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "        scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "        classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "        num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "\n",
    "        for idx, image_path in enumerate(TEST_IMAGE_PATHS):\n",
    "            image_data = tf.read_file(image_path)\n",
    "            image_decoded = tf.image.decode_image(image_data)\n",
    "            image_np = sess.run(image_decoded)\n",
    "            original_shape = image_np.shape\n",
    "\n",
    "            # Initialize\n",
    "            adv_image = image_np.copy()\n",
    "\n",
    "            # Downsample the adversarial image for approximating gradient\n",
    "            adv_image_low_res = downsample(adv_image, FACTOR)\n",
    "            adv_image_low_res_expanded = np.expand_dims(adv_image_low_res, axis=0)\n",
    "\n",
    "            # save iteration images\n",
    "            iteration_save_dir = os.path.join(SAVE_DIR, f'iteration_{idx}')\n",
    "            if not os.path.exists(iteration_save_dir):\n",
    "                os.makedirs(iteration_save_dir)\n",
    "\n",
    "            # Iteration\n",
    "            for i in range(NUM_ITERATIONS):\n",
    "                print(f\"Iteration {i + 1}\")\n",
    "\n",
    "                # Compute the approximate gradient on low-res image\n",
    "                grad_approx_low_res = approximate_gradient(sess, adv_image_low_res_expanded, detection_graph, num_samples=NUM_SAMPLES)\n",
    "\n",
    "                # Upsample gradient to original resolution\n",
    "                grad_approx = upsample(grad_approx_low_res[0], original_shape)\n",
    "\n",
    "                # Update adversarial image\n",
    "                adv_image = adv_image + np.clip(EPS * grad_approx, -SAT, SAT)\n",
    "\n",
    "                adv_image = np.clip(adv_image, 0, 255).astype(np.uint8)\n",
    "\n",
    "                # Save the current adversarial image without boxes\n",
    "                plt.imsave(os.path.join(iteration_save_dir, f'adv_image_iteration_{i + 1}.jpg'), adv_image)\n",
    "\n",
    "                # Test the adversarial image on the model\n",
    "                adv_image_expanded = np.expand_dims(adv_image, axis=0)\n",
    "                (iter_boxes, iter_scores, iter_classes, iter_num_detections) = sess.run(\n",
    "                    [boxes, scores, classes, num_detections],\n",
    "                    feed_dict={image_tensor: adv_image_expanded}\n",
    "                )\n",
    "                \n",
    "                # Print detection results for the current iteration\n",
    "                for j, score in enumerate(np.squeeze(iter_scores)):\n",
    "                    if score > 0.5:\n",
    "                        class_id = int(np.squeeze(iter_classes)[j])\n",
    "                        class_name = category_index[class_id]['name']\n",
    "                        print(f\"Iteration {i + 1}: Detected class: {class_name}, Confidence Score: {score:.8f}\")\n",
    "\n",
    "                # Visualize the detection results\n",
    "                adv_image_visual = adv_image.copy()\n",
    "                vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "                    adv_image_visual, \n",
    "                    np.squeeze(iter_boxes),\n",
    "                    np.squeeze(iter_classes).astype(np.int32),\n",
    "                    np.squeeze(iter_scores),\n",
    "                    category_index,\n",
    "                    use_normalized_coordinates=True,\n",
    "                    line_thickness=6,\n",
    "                    min_score_thresh=0.5\n",
    "                )\n",
    "\n",
    "                # Display the current adversarial image with bounding boxes\n",
    "                plt.figure(figsize=IMAGE_SIZE)\n",
    "                plt.axis('off')\n",
    "                plt.imshow(adv_image_visual) \n",
    "                plt.title(f\"Iteration {i + 1} Detection Results\")\n",
    "                plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm 2: Adversarial pattern generation on downsampled image, using the sign of gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f# Tuning parameters\n",
    "FACTOR = 0.2\n",
    "H = 5\n",
    "NUM_SAMPLES = 500\n",
    "NUM_ITERATIONS = 40\n",
    "EPS = 25\n",
    "\n",
    "SAVE_DIR = 'saved_image_2'\n",
    "if not os.path.exists(SAVE_DIR):\n",
    "    os.makedirs(SAVE_DIR)\n",
    "\n",
    "\n",
    "def approximate_gradient(sess, image_np_expanded, detection_graph, h=H, num_samples=NUM_SAMPLES):\n",
    "    original_loss = compute_loss(sess, image_np_expanded, detection_graph)\n",
    "    grad_approx = np.zeros_like(image_np_expanded).astype(np.float32)\n",
    "    \n",
    "    total_pixels = np.prod(image_np_expanded.shape)\n",
    "    \n",
    "    # Randomly selecting pixel indices from the entire image\n",
    "    indices = np.random.choice(total_pixels, num_samples, replace=False)\n",
    "        \n",
    "    for flat_idx in indices:\n",
    "        idx = np.unravel_index(flat_idx, image_np_expanded.shape)\n",
    "        perturb = np.zeros_like(image_np_expanded)\n",
    "        perturb[idx] = h\n",
    "        perturbed_image = image_np_expanded + perturb\n",
    "        perturbed_loss = compute_loss(sess, perturbed_image, detection_graph)\n",
    "        grad_approx[idx] = (perturbed_loss - original_loss) / h \n",
    "\n",
    "    return grad_approx\n",
    "\n",
    "# Main execution\n",
    "with detection_graph.as_default():\n",
    "    with tf.Session(graph=detection_graph) as sess:\n",
    "        image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "        boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "        scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "        classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "        num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "\n",
    "        for idx, image_path in enumerate(TEST_IMAGE_PATHS):\n",
    "            image_data = tf.read_file(image_path)\n",
    "            image_decoded = tf.image.decode_image(image_data)\n",
    "            image_np = sess.run(image_decoded)\n",
    "            original_shape = image_np.shape\n",
    "\n",
    "            # Initialize\n",
    "            adv_image = image_np.copy()\n",
    "\n",
    "            # Downsample the adversarial image for approximating gradient\n",
    "            adv_image_low_res = downsample(adv_image, FACTOR)\n",
    "            adv_image_low_res_expanded = np.expand_dims(adv_image_low_res, axis=0)\n",
    "\n",
    "            # save iteration images\n",
    "            iteration_save_dir = os.path.join(SAVE_DIR, f'iteration_{idx}')\n",
    "            if not os.path.exists(iteration_save_dir):\n",
    "                os.makedirs(iteration_save_dir)\n",
    "\n",
    "            # Iteration\n",
    "            for i in range(NUM_ITERATIONS):\n",
    "                print(f\"Iteration {i + 1}\")\n",
    "\n",
    "                # Compute the approximate gradient on low-res image\n",
    "                grad_approx_low_res = approximate_gradient(sess, adv_image_low_res_expanded, detection_graph, num_samples=NUM_SAMPLES)\n",
    "\n",
    "                # Upsample gradient to original resolution\n",
    "                grad_approx = upsample(grad_approx_low_res[0], original_shape)\n",
    "                # Update adversarial image\n",
    "                adv_image = adv_image + EPS * np.sign(grad_approx)\n",
    "\n",
    "                adv_image = np.clip(adv_image, 0, 255).astype(np.uint8)\n",
    "\n",
    "                # Save the current adversarial image without boxes\n",
    "                plt.imsave(os.path.join(iteration_save_dir, f'adv_image_iteration_{i + 1}.jpg'), adv_image)\n",
    "\n",
    "                # Test the adversarial image on the model\n",
    "                adv_image_expanded = np.expand_dims(adv_image, axis=0)\n",
    "                (iter_boxes, iter_scores, iter_classes, iter_num_detections) = sess.run(\n",
    "                    [boxes, scores, classes, num_detections],\n",
    "                    feed_dict={image_tensor: adv_image_expanded}\n",
    "                )\n",
    "                \n",
    "                # Print detection results for the current iteration\n",
    "                for j, score in enumerate(np.squeeze(iter_scores)):\n",
    "                    if score > 0.5:\n",
    "                        class_id = int(np.squeeze(iter_classes)[j])\n",
    "                        class_name = category_index[class_id]['name']\n",
    "                        print(f\"Iteration {i + 1}: Detected class: {class_name}, Confidence Score: {score:.8f}\")\n",
    "\n",
    "                # Visualize the detection results\n",
    "                adv_image_visual = adv_image.copy()\n",
    "                vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "                    adv_image_visual, \n",
    "                    np.squeeze(iter_boxes),\n",
    "                    np.squeeze(iter_classes).astype(np.int32),\n",
    "                    np.squeeze(iter_scores),\n",
    "                    category_index,\n",
    "                    use_normalized_coordinates=True,\n",
    "                    line_thickness=6,\n",
    "                    min_score_thresh=0.5\n",
    "                )\n",
    "\n",
    "                # Display the current adversarial image with bounding boxes\n",
    "                plt.figure(figsize=IMAGE_SIZE)\n",
    "                plt.axis('off')\n",
    "                plt.imshow(adv_image_visual) \n",
    "                plt.title(f\"Iteration {i + 1} Detection Results\")\n",
    "                plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm 3: Adversarial pattern generation on downsampled image, using the gradient without saturator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuning parameters\n",
    "FACTOR = 0.2\n",
    "H = 5\n",
    "NUM_SAMPLES = 500\n",
    "NUM_ITERATIONS = 40\n",
    "EPS = 200000\n",
    "\n",
    "SAVE_DIR = 'saved_image_3'\n",
    "if not os.path.exists(SAVE_DIR):\n",
    "    os.makedirs(SAVE_DIR)\n",
    "\n",
    "\n",
    "def approximate_gradient(sess, image_np_expanded, detection_graph, h=H, num_samples=NUM_SAMPLES):\n",
    "    original_loss = compute_loss(sess, image_np_expanded, detection_graph)\n",
    "    grad_approx = np.zeros_like(image_np_expanded).astype(np.float32)\n",
    "    \n",
    "    total_pixels = np.prod(image_np_expanded.shape)\n",
    "    \n",
    "    # Randomly selecting pixel indices from the entire image\n",
    "    indices = np.random.choice(total_pixels, num_samples, replace=False)\n",
    "        \n",
    "    for flat_idx in indices:\n",
    "        idx = np.unravel_index(flat_idx, image_np_expanded.shape)\n",
    "        perturb = np.zeros_like(image_np_expanded)\n",
    "        perturb[idx] = h\n",
    "        perturbed_image = image_np_expanded + perturb\n",
    "        perturbed_loss = compute_loss(sess, perturbed_image, detection_graph)\n",
    "        grad_approx[idx] = (perturbed_loss - original_loss) / h \n",
    "\n",
    "    return grad_approx\n",
    "\n",
    "# Main execution\n",
    "with detection_graph.as_default():\n",
    "    with tf.Session(graph=detection_graph) as sess:\n",
    "        image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "        boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "        scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "        classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "        num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "\n",
    "        for idx, image_path in enumerate(TEST_IMAGE_PATHS):\n",
    "            image_data = tf.read_file(image_path)\n",
    "            image_decoded = tf.image.decode_image(image_data)\n",
    "            image_np = sess.run(image_decoded)\n",
    "            original_shape = image_np.shape\n",
    "\n",
    "            # Initialize\n",
    "            adv_image = image_np.copy()\n",
    "\n",
    "            # Downsample the adversarial image for approximating gradient\n",
    "            adv_image_low_res = downsample(adv_image, FACTOR)\n",
    "            adv_image_low_res_expanded = np.expand_dims(adv_image_low_res, axis=0)\n",
    "\n",
    "            # save iteration images\n",
    "            iteration_save_dir = os.path.join(SAVE_DIR, f'iteration_{idx}')\n",
    "            if not os.path.exists(iteration_save_dir):\n",
    "                os.makedirs(iteration_save_dir)\n",
    "\n",
    "            # Iteration\n",
    "            for i in range(NUM_ITERATIONS):\n",
    "                print(f\"Iteration {i + 1}\")\n",
    "\n",
    "                # Compute the approximate gradient on low-res image\n",
    "                grad_approx_low_res = approximate_gradient(sess, adv_image_low_res_expanded, detection_graph, num_samples=NUM_SAMPLES)\n",
    "\n",
    "                # Upsample gradient to original resolution\n",
    "                grad_approx = upsample(grad_approx_low_res[0], original_shape)\n",
    "\n",
    "                # Update adversarial image\n",
    "                adv_image = adv_image + EPS * grad_approx\n",
    "\n",
    "\n",
    "                adv_image = np.clip(adv_image, 0, 255).astype(np.uint8)\n",
    "\n",
    "                # Save the current adversarial image without boxes\n",
    "                plt.imsave(os.path.join(iteration_save_dir, f'adv_image_iteration_{i + 1}.jpg'), adv_image)\n",
    "\n",
    "                # Test the adversarial image on the model\n",
    "                adv_image_expanded = np.expand_dims(adv_image, axis=0)\n",
    "                (iter_boxes, iter_scores, iter_classes, iter_num_detections) = sess.run(\n",
    "                    [boxes, scores, classes, num_detections],\n",
    "                    feed_dict={image_tensor: adv_image_expanded}\n",
    "                )\n",
    "                \n",
    "                # Print detection results for the current iteration\n",
    "                for j, score in enumerate(np.squeeze(iter_scores)):\n",
    "                    if score > 0.5:\n",
    "                        class_id = int(np.squeeze(iter_classes)[j])\n",
    "                        class_name = category_index[class_id]['name']\n",
    "                        print(f\"Iteration {i + 1}: Detected class: {class_name}, Confidence Score: {score:.8f}\")\n",
    "\n",
    "                # Visualize the detection results\n",
    "                adv_image_visual = adv_image.copy()\n",
    "                vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "                    adv_image_visual, \n",
    "                    np.squeeze(iter_boxes),\n",
    "                    np.squeeze(iter_classes).astype(np.int32),\n",
    "                    np.squeeze(iter_scores),\n",
    "                    category_index,\n",
    "                    use_normalized_coordinates=True,\n",
    "                    line_thickness=6,\n",
    "                    min_score_thresh=0.5\n",
    "                )\n",
    "\n",
    "                # Display the current adversarial image with bounding boxes\n",
    "                plt.figure(figsize=IMAGE_SIZE)\n",
    "                plt.axis('off')\n",
    "                plt.imshow(adv_image_visual) \n",
    "                plt.title(f\"Iteration {i + 1} Detection Results\")\n",
    "                plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
