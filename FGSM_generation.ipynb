{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running on new images\n",
    "This notebook will walk you step by step through the process of using a pre-trained model to detect traffic signs in an image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "# tf.enable_eager_execution()\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "# from PIL import Image\n",
    "import glob as glob\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import sys\n",
    "\n",
    "%matplotlib inline\n",
    "# tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sys.path.append('../models/research')  # Replace with the path to TensorFlow Object Detection API\n",
    "sys.path.append('../darkflow')  # Replace with the path to Darkflow\n",
    "\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Object Detection API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL_NAME = 'faster_rcnn_inception_resnet_v2_atrous'\n",
    "# MODEL_NAME = 'faster_rcnn_resnet_101'\n",
    "# MODEL_NAME = 'faster_rcnn_resnet50'\n",
    "MODEL_NAME = 'faster_rcnn_inception_v2'\n",
    "# MODEL_NAME = 'rfcn_resnet101'\n",
    "# MODEL_NAME = 'ssd_inception_v2'\n",
    "# MODEL_NAME = 'ssd_mobilenet_v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to frozen detection graph. This is the actual model that is used for the traffic sign detection.\n",
    "MODEL_PATH = os.path.join('models', MODEL_NAME)\n",
    "PATH_TO_CKPT = os.path.join(MODEL_PATH,'inference_graph/frozen_inference_graph.pb')\n",
    "\n",
    "# List of the strings that is used to add correct label for each box.\n",
    "PATH_TO_LABELS = os.path.join('gtsdb_data', 'gtsdb3_label_map.pbtxt')\n",
    "\n",
    "NUM_CLASSES = 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a (frozen) Tensorflow model into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "    od_graph_def = tf.GraphDef()\n",
    "    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading label map\n",
    "Label maps map indices to category names, so that when our convolution network predicts `2`, we know that this corresponds to `mandatory`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/yuxing/my_project/envpy3.6/lib/python3.6/site-packages/object_detection/utils/label_map_util.py:132: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "item {\n",
      "  name: \"prohibitory\"\n",
      "  id: 1\n",
      "}\n",
      "item {\n",
      "  name: \"mandatory\"\n",
      "  id: 2\n",
      "}\n",
      "item {\n",
      "  name: \"danger\"\n",
      "  id: 3\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PATH_TO_LABELS = '/home/yuxing/my_project/traffic-sign-detection/gtsdb_data/gtsdb3_label_map.pbtxt'\n",
    "\n",
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)\n",
    "print(label_map)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_into_numpy_array(image):\n",
    "    (im_width, im_height) = image.size\n",
    "    #return np.array(image.getdata()).reshape((im_height, im_width, 3)).astype(np.uint8)\n",
    "    return np.array(image.getdata()).reshape((im_height, im_width, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PATH_TO_TEST_IMAGES_DIR = '/home/yuxing/my_project/traffic-sign-detection/test_images'\n",
    "\n",
    "TEST_IMAGE_PATHS = glob.glob(os.path.join(PATH_TO_TEST_IMAGES_DIR, '*.jpg'))\n",
    "\n",
    "# Size, in inches, of the output images.\n",
    "IMAGE_SIZE = (20, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "saved_detection_results = {}\n",
    "\n",
    "# Run inference and visualization\n",
    "with detection_graph.as_default():\n",
    "    with tf.Session(graph=detection_graph) as sess:\n",
    "        for idx, image_path in enumerate(TEST_IMAGE_PATHS):\n",
    "            image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "            boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "            scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "            classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "            num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "\n",
    "            image_data = tf.read_file(image_path)\n",
    "            image_decoded = tf.image.decode_image(image_data)\n",
    "            image_np = sess.run(image_decoded)\n",
    "            image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "\n",
    "            (boxes, scores, classes, num_detections) = sess.run(\n",
    "                [boxes, scores, classes, num_detections],\n",
    "                feed_dict={image_tensor: image_np_expanded})\n",
    "\n",
    "            saved_detection_results[image_path] = {\n",
    "                'boxes': boxes,\n",
    "                'scores': scores,\n",
    "                'classes': classes,\n",
    "                'num_detections': num_detections\n",
    "            }\n",
    "\n",
    "            vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "                image_np,\n",
    "                np.squeeze(boxes),\n",
    "                np.squeeze(classes).astype(np.int32),\n",
    "                np.squeeze(scores),\n",
    "                category_index,\n",
    "                use_normalized_coordinates=True,\n",
    "                line_thickness=6)\n",
    "            plt.figure(idx, figsize=IMAGE_SIZE)\n",
    "            plt.axis('off')\n",
    "            plt.imshow(image_np)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of boxes: (1, 300, 4)\n",
      "Shape of scores: (1, 300)\n",
      "Shape of classes: (1, 300)\n",
      "Shape of num_detections: (1,)\n",
      "WARNING:tensorflow:From /home/yuxing/my_project/envpy3.6/lib/python3.6/site-packages/tensorflow/python/ops/losses/losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Target Class: 3\n",
      "Gradient tensor: None\n",
      "Gradient is None.\n",
      "Shape of boxes: (1, 300, 4)\n",
      "Shape of scores: (1, 300)\n",
      "Shape of classes: (1, 300)\n",
      "Shape of num_detections: (1,)\n",
      "Target Class: 3\n",
      "Gradient tensor: None\n",
      "Gradient is None.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with detection_graph.as_default():\n",
    "    with tf.Session(graph=detection_graph) as sess:\n",
    "        for idx, image_path in enumerate(TEST_IMAGE_PATHS):\n",
    "            \n",
    "            image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "            boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "            scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "            classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "            num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "            \n",
    "            image_data = tf.read_file(image_path)\n",
    "            image_decoded = tf.image.decode_image(image_data)\n",
    "            image_np = sess.run(image_decoded)\n",
    "            image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "            \n",
    "            (boxes, scores, classes, num_detections) = sess.run(\n",
    "                [boxes, scores, classes, num_detections],\n",
    "                feed_dict={image_tensor: image_np_expanded})\n",
    "            \n",
    "            print(\"Shape of boxes:\", boxes.shape)\n",
    "            print(\"Shape of scores:\", scores.shape)\n",
    "            print(\"Shape of classes:\", classes.shape)\n",
    "            print(\"Shape of num_detections:\", num_detections.shape)\n",
    "\n",
    "            \n",
    "            # Take the detection with the highest score\n",
    "            max_score_index = np.argmax(scores)\n",
    "            target_class = int(classes[0][max_score_index])\n",
    "            target_score = scores[0][max_score_index]\n",
    "            \n",
    "            # Inverting the scores to approximate logits (this is an approximation)\n",
    "            approx_logits = np.log(target_score / (1 - target_score))\n",
    "        \n",
    "            # Adjust target_class index\n",
    "            adjusted_target_class = target_class - 1  # Now it should be between 0 and NUM_CLASSES - 1\n",
    "\n",
    "            # Create a tensor for logits\n",
    "            logits_tensor = np.zeros(NUM_CLASSES)\n",
    "\n",
    "            # Now adjusted_target_class will be within the bounds\n",
    "            logits_tensor[adjusted_target_class] = approx_logits\n",
    "            \n",
    "            # Define the loss after knowing target class\n",
    "            target_label = tf.placeholder(tf.int32, shape=(), name='target_label')\n",
    "            \n",
    "            loss_object = tf.losses.softmax_cross_entropy(\n",
    "                onehot_labels=tf.one_hot([target_label], NUM_CLASSES),\n",
    "                logits=logits_tensor  # Changed this line\n",
    "            )\n",
    "            \n",
    "            grads = tf.gradients(loss_object, image_tensor)[0]  # Adding [0] to get the first element\n",
    "            \n",
    "            # Print target class and gradient tensor\n",
    "            print(f\"Target Class: {target_class}\")\n",
    "            print(f\"Gradient tensor: {grads}\")\n",
    "            \n",
    "            if grads is None:\n",
    "                print(\"Gradient is None.\")\n",
    "                continue\n",
    "            \n",
    "            feed_dict = {\n",
    "                image_tensor: image_np_expanded,\n",
    "                target_label: target_class\n",
    "            }\n",
    "            \n",
    "            adv_grads_val = sess.run(grads, feed_dict=feed_dict)\n",
    "            \n",
    "            # Create adversarial image\n",
    "            eps = 0.3\n",
    "            adv_image = image_np + eps * np.sign(adv_grads_val)\n",
    "            adv_image = np.clip(adv_image, 0, 255).astype(np.uint8)\n",
    "\n",
    "            # Visualize the adversarial image\n",
    "            plt.figure(idx, figsize=IMAGE_SIZE)\n",
    "            plt.axis('off')\n",
    "            plt.imshow(adv_image[0])\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
