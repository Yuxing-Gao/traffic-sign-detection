{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running on new images\n",
    "This notebook will walk you step by step through the process of using a pre-trained model to detect traffic signs in an image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import glob as glob\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import sys\n",
    "import cv2\n",
    "import csv\n",
    "\n",
    "%matplotlib inline\n",
    "# tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_threshold = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sys.path.append('/Users/yuxing/traffic-sign-detection/models/research')  # Replace with the path to TensorFlow Object Detection API\n",
    "# sys.path.append('../darkflow')  # Replace with the path to Darkflow\n",
    "\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model preparation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Object Detection API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL_NAME = 'faster_rcnn_inception_resnet_v2_atrous'\n",
    "# MODEL_NAME = 'faster_rcnn_resnet_101'\n",
    "# MODEL_NAME = 'faster_rcnn_resnet50'\n",
    "MODEL_NAME = 'faster_rcnn_inception_v2'\n",
    "# MODEL_NAME = 'rfcn_resnet101'\n",
    "# MODEL_NAME = 'ssd_inception_v2'\n",
    "# MODEL_NAME = 'ssd_mobilenet_v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to frozen detection graph. This is the actual model that is used for the traffic sign detection.\n",
    "MODEL_PATH = os.path.join('models', MODEL_NAME)\n",
    "PATH_TO_CKPT = os.path.join(MODEL_PATH,'inference_graph/frozen_inference_graph.pb')\n",
    "\n",
    "# List of the strings that is used to add correct label for each box.\n",
    "PATH_TO_LABELS = os.path.join('gtsdb_data', 'gtsdb3_label_map.pbtxt')\n",
    "\n",
    "NUM_CLASSES = 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a (frozen) Tensorflow model into memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "    od_graph_def = tf.GraphDef()\n",
    "    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading label map\n",
    "Label maps map indices to category names, so that when our convolution network predicts `2`, we know that this corresponds to `mandatory`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_LABELS = '/Users/yuxing/traffic-sign-detection/gtsdb_data/gtsdb_label_map.pbtxt'\n",
    "\n",
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)\n",
    "# print(label_map)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_into_numpy_array(image):\n",
    "    (im_width, im_height) = image.size\n",
    "    #return np.array(image.getdata()).reshape((im_height, im_width, 3)).astype(np.uint8)\n",
    "    return np.array(image.getdata()).reshape((im_height, im_width, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PATH_TO_TEST_IMAGES_DIR = '/Users/yuxing/traffic-sign-detection/test_images'\n",
    "\n",
    "TEST_IMAGE_PATHS = glob.glob(os.path.join(PATH_TO_TEST_IMAGES_DIR, '*.jpg'))\n",
    "\n",
    "# Size, in inches, of the output images.\n",
    "IMAGE_SIZE = (20, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def append_results(results, image_name, iteration, class_name, score, box, sum_diff, max_diff):\n",
    "    results.append({\n",
    "        'image_name': image_name,\n",
    "        'iteration': iteration + 1,\n",
    "        'class': class_name,\n",
    "        'score': float(score),\n",
    "        'box': box,\n",
    "        'total_perturbation': sum_diff,\n",
    "        'max_perturbation': max_diff\n",
    "    })\n",
    "\n",
    "def save_results_to_csv(results, image_index, save_dir, algorithm_number):\n",
    "    csv_filename = f\"adv_alg{algorithm_number}_results.csv\"\n",
    "    csv_path = os.path.join(save_dir, csv_filename)\n",
    "    \n",
    "    # Check if file exists\n",
    "    file_exists = os.path.isfile(csv_path)\n",
    "    \n",
    "    with open(csv_path, 'a', newline='') as csvfile:\n",
    "        # Include 'image_index' in the fieldnames\n",
    "        fieldnames = ['image_index', 'image_name', 'iteration', 'class', 'score', 'box', 'total_perturbation', 'max_perturbation']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "   \n",
    "        if not file_exists:\n",
    "            writer.writeheader()\n",
    "        \n",
    "        for result in results:\n",
    "            # Include image_index\n",
    "            result['image_index'] = image_index + 1\n",
    "            writer.writerow(result)\n",
    "\n",
    "# # Run inference and visualization\n",
    "# with detection_graph.as_default():\n",
    "#     with tf.Session(graph=detection_graph) as sess:\n",
    "#         for idx, image_path in enumerate(TEST_IMAGE_PATHS):\n",
    "#             image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "#             boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "#             scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "#             classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "#             num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "\n",
    "#             image_data = tf.read_file(image_path)\n",
    "#             image_decoded = tf.image.decode_image(image_data)\n",
    "#             image_np = sess.run(image_decoded)\n",
    "#             image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "\n",
    "#             (boxes, scores, classes, num_detections) = sess.run(\n",
    "#                 [boxes, scores, classes, num_detections],\n",
    "#                 feed_dict={image_tensor: image_np_expanded})\n",
    "            \n",
    "#             vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "#                 image_np,\n",
    "#                 np.squeeze(boxes),\n",
    "#                 np.squeeze(classes).astype(np.int32),\n",
    "#                 np.squeeze(scores),\n",
    "#                 category_index,\n",
    "#                 use_normalized_coordinates=True,\n",
    "#                 line_thickness=6)\n",
    "#             plt.figure(idx, figsize=IMAGE_SIZE)\n",
    "#             plt.axis('off')\n",
    "#             plt.imshow(image_np)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_number = 0  # Adjust this for different algorithms\n",
    "\n",
    "SAVE_DIR = 'test_image_results'\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# Run inference and visualization\n",
    "with detection_graph.as_default():\n",
    "    with tf.Session(graph=detection_graph) as sess:\n",
    "        for idx, image_path in enumerate(TEST_IMAGE_PATHS):\n",
    "            image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "            boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "            scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "            classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "            num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "\n",
    "            image_data = tf.read_file(image_path)\n",
    "            image_decoded = tf.image.decode_image(image_data)\n",
    "            image_np = sess.run(image_decoded)\n",
    "            image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "\n",
    "            (boxes, scores, classes, num_detections) = sess.run(\n",
    "                [boxes, scores, classes, num_detections],\n",
    "                feed_dict={image_tensor: image_np_expanded})\n",
    "            \n",
    "            # Get the image name from the image path\n",
    "            image_name = os.path.basename(image_path)\n",
    "\n",
    "            # Record the original image detections\n",
    "            original_results = []\n",
    "            for i in range(len(np.squeeze(scores))):\n",
    "                if np.squeeze(scores)[i] > score_threshold:\n",
    "                    class_id = int(np.squeeze(classes)[i])\n",
    "                    class_name = category_index[class_id]['name']\n",
    "                    box = np.squeeze(boxes)[i].tolist()\n",
    "                    append_results(original_results, image_name, -1, class_name, np.squeeze(scores)[i], box, 0, 0)\n",
    "            \n",
    "            # Save original image results to CSV\n",
    "            save_results_to_csv(original_results, idx, SAVE_DIR, algorithm_number)\n",
    "\n",
    "            vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "                image_np,\n",
    "                np.squeeze(boxes),\n",
    "                np.squeeze(classes).astype(np.int32),\n",
    "                np.squeeze(scores),\n",
    "                category_index,\n",
    "                use_normalized_coordinates=True,\n",
    "                line_thickness=6)\n",
    "            plt.figure(idx, figsize=IMAGE_SIZE)\n",
    "            plt.axis('off')\n",
    "            plt.imshow(image_np)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def region_downsample(image_region, factor):\n",
    "    return cv2.resize(image_region, None, fx=factor, fy=factor, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "def region_upsample(image_region, target_shape):\n",
    "    return cv2.resize(image_region, (target_shape[1], target_shape[0]), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "def compute_loss(sess, image_np_expanded, detection_graph):\n",
    "    image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "    scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "    classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "    boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "    \n",
    "    (scores, classes) = sess.run([scores, classes], feed_dict={image_tensor: image_np_expanded})\n",
    "    max_score_index = np.argmax(scores)\n",
    "    score = scores[0][max_score_index]\n",
    "    approx_logits = np.log(score / (1 - score))\n",
    "    return approx_logits\n",
    "\n",
    "def approximate_gradient(sess, image_np_expanded, detection_graph, h, num_samples):\n",
    "    original_loss = compute_loss(sess, image_np_expanded, detection_graph)\n",
    "    grad_approx = np.zeros_like(image_np_expanded).astype(np.float32)\n",
    "    \n",
    "    total_pixels = np.prod(image_np_expanded.shape)\n",
    "    num_samples = min(num_samples, total_pixels)  # Adjust the num_samples value if total_pixels is less than NUM_SAMPLES\n",
    "    indices = np.random.choice(total_pixels, num_samples, replace=False)  # Randomly selecting pixel indices from the entire image\n",
    "        \n",
    "    for flat_idx in indices:\n",
    "        idx = np.unravel_index(flat_idx, image_np_expanded.shape)\n",
    "        perturb = np.zeros_like(image_np_expanded)\n",
    "        perturb[idx] = h\n",
    "        perturbed_image = image_np_expanded + perturb\n",
    "        perturbed_loss = compute_loss(sess, perturbed_image, detection_graph)\n",
    "        grad_approx[idx] = (perturbed_loss - original_loss) / h \n",
    "\n",
    "    return grad_approx\n",
    "\n",
    "def save_adversarial_image(image, idx, iteration, save_dir, algorithm_number):\n",
    "    image_name = f\"alg{algorithm_number}_{idx + 1:03d}_itr{iteration + 1}.jpg\"\n",
    "    image_save_path = os.path.join(save_dir, image_name)\n",
    "    plt.imsave(image_save_path, image)\n",
    "    return image_name\n",
    "\n",
    "def save_adversarial_image(image, idx, iteration, save_dir, algorithm_number):\n",
    "    image_name = f\"alg{algorithm_number}_{idx + 1:03d}_itr{iteration + 1}.jpg\"\n",
    "    image_save_path = os.path.join(save_dir, image_name)\n",
    "    plt.imsave(image_save_path, image)\n",
    "    return image_name\n",
    "\n",
    "def process_bounding_boxes(sess, adv_image, boxes_tensor, scores_tensor, classes_tensor, num_detections_tensor, image_tensor, score_threshold, buffer_factor, original_shape, factor, num_samples, h):\n",
    "    grad_approx = np.zeros_like(adv_image).astype(np.float32)\n",
    "    \n",
    "    # Fetch the original detections to compute bounding boxes\n",
    "    (initial_boxes, initial_scores, _, _) = sess.run(\n",
    "        [boxes_tensor, scores_tensor, classes_tensor, num_detections_tensor],\n",
    "        feed_dict={image_tensor: np.expand_dims(adv_image, axis=0)}\n",
    "    )\n",
    "    initial_boxes = np.squeeze(initial_boxes)\n",
    "    initial_scores = np.squeeze(initial_scores)\n",
    "\n",
    "    valid_indices = np.where(initial_scores > score_threshold)[0]  # Filter detections based on threshold\n",
    "\n",
    "    # For each valid detection\n",
    "    for valid_idx in valid_indices:\n",
    "        valid_box = initial_boxes[valid_idx]\n",
    "        ymin, xmin, ymax, xmax = valid_box\n",
    "        height, width = ymax - ymin, xmax - xmin\n",
    "\n",
    "        ymin = max(0, ymin - buffer_factor * height)\n",
    "        xmin = max(0, xmin - buffer_factor * width)\n",
    "        ymax = min(1, ymax + buffer_factor * height)\n",
    "        xmax = min(1, xmax + buffer_factor * width)\n",
    "\n",
    "        ymin, xmin, ymax, xmax = int(ymin * original_shape[0]), int(xmin * original_shape[1]), int(ymax * original_shape[0]), int(xmax * original_shape[1])\n",
    "\n",
    "        if ymax - ymin > 0 and xmax - xmin > 0:\n",
    "            region = adv_image[ymin:ymax, xmin:xmax]\n",
    "            region_low_res = region_downsample(region, factor)\n",
    "            region_low_res_expanded = np.expand_dims(region_low_res, axis=0)\n",
    "\n",
    "            # Compute the approximate gradient on low-res region\n",
    "            region_grad_approx_low_res = approximate_gradient(sess, region_low_res_expanded, detection_graph, h, num_samples)\n",
    "            # Upsample gradient back to original resolution of that region\n",
    "            region_grad_approx = region_upsample(region_grad_approx_low_res[0], region.shape)\n",
    "\n",
    "            grad_approx[ymin:ymax, xmin:xmax] = region_grad_approx\n",
    "\n",
    "    return grad_approx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Based Method (adversarial pattern only generated in and around bounding boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuning parameters\n",
    "FACTOR = 0.4\n",
    "H = 10\n",
    "NUM_SAMPLES = 50\n",
    "NUM_ITERATIONS = 10\n",
    "EPS = 40000\n",
    "BUFFER_FACTOR =1\n",
    "algorithm_number = 1\n",
    "\n",
    "SAVE_DIR = 'saved_images_1'\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# Main execution\n",
    "with detection_graph.as_default():\n",
    "    with tf.Session(graph=detection_graph) as sess:\n",
    "        image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "        boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "        scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "        classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "        num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "\n",
    "        for idx, image_path in enumerate(TEST_IMAGE_PATHS):\n",
    "            image_data = tf.read_file(image_path)\n",
    "            image_decoded = tf.image.decode_image(image_data)\n",
    "            image_np = sess.run(image_decoded)\n",
    "            original_shape = image_np.shape\n",
    "\n",
    "            adv_image = image_np.copy()\n",
    "            last_adv_image = np.copy(adv_image)  # To calculate the difference per iteration\n",
    "            results = []\n",
    "\n",
    "            # Iteration based on images\n",
    "            for i in range(NUM_ITERATIONS):\n",
    "                grad_approx = process_bounding_boxes(\n",
    "                    sess, adv_image, boxes, scores, classes, num_detections, image_tensor, 0.5, \n",
    "                    BUFFER_FACTOR, original_shape, FACTOR, NUM_SAMPLES, H\n",
    "                )\n",
    "\n",
    "                perturbed_adv_image = adv_image + EPS * grad_approx  # Perturb the image\n",
    "\n",
    "                # Calculate the total and max perturbation before clipping\n",
    "                per_box_diff = perturbed_adv_image - last_adv_image\n",
    "                sum_diff = np.sum(np.abs(per_box_diff), axis=(0, 1, 2))\n",
    "                max_diff = np.max(np.abs(per_box_diff), axis=(0, 1, 2))\n",
    "\n",
    "                print(f\"Test Image {idx + 1}, Iteration {i + 1}:\")\n",
    "                print(f\"Sum_diff: {sum_diff}\")\n",
    "                print(f\"Max_diff: {max_diff}\")\n",
    "\n",
    "                # Initialize a flag to check if any scores are above the threshold\n",
    "                any_above_threshold = False\n",
    "\n",
    "                # Update the last_adv_image with the perturbed values before clipping\n",
    "                last_adv_image = perturbed_adv_image.copy()\n",
    "\n",
    "                # Apply clipping to keep pixel values valid for visualizing and further processing\n",
    "                adv_image = np.clip(perturbed_adv_image, 0, 255).astype(np.uint8)\n",
    "\n",
    "                # Save the adversarial image and get the image name\n",
    "                image_name = save_adversarial_image(adv_image, idx, i, SAVE_DIR, algorithm_number)\n",
    "\n",
    "                adv_image_expanded = np.expand_dims(adv_image, axis=0)\n",
    "                (iter_boxes, iter_scores, iter_classes, iter_num_detections) = sess.run(\n",
    "                    [boxes, scores, classes, num_detections],\n",
    "                    feed_dict={image_tensor: adv_image_expanded}\n",
    "                )\n",
    "                \n",
    "                # Save perturbation details per box\n",
    "                for j, score in enumerate(np.squeeze(iter_scores)):\n",
    "                    if score > score_threshold:\n",
    "                        any_above_threshold = True\n",
    "                        class_id = int(np.squeeze(iter_classes)[j])\n",
    "                        class_name = category_index[class_id]['name']\n",
    "                        box = np.squeeze(iter_boxes)[j].tolist()\n",
    "                        append_results(results, image_name, i, class_name, score, box, sum_diff, max_diff)\n",
    "                        print(f\"Detected class: {class_name}, Confidence Score: {score:.8f}\")\n",
    "\n",
    "                # If no scores were above threshold, record the max and sum diff\n",
    "                if not any_above_threshold:\n",
    "                    append_results(results, image_name, i, \"no_detection\", 0, [0, 0, 0, 0], sum_diff, max_diff)\n",
    "\n",
    "\n",
    "                # Visualization of the results\n",
    "                adv_image_visual = adv_image.copy()\n",
    "                vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "                    adv_image_visual, \n",
    "                    np.squeeze(iter_boxes),\n",
    "                    np.squeeze(iter_classes).astype(np.int32),\n",
    "                    np.squeeze(iter_scores),\n",
    "                    category_index,\n",
    "                    use_normalized_coordinates=True,\n",
    "                    line_thickness=6,\n",
    "                    min_score_thresh=0.5\n",
    "                )\n",
    "\n",
    "                # Save the visualized image with boxes\n",
    "                save_adversarial_image_with_boxes(adv_image_visual, idx, i, SAVE_DIR, algorithm_number)\n",
    "\n",
    "\n",
    "                plt.figure(figsize=IMAGE_SIZE)\n",
    "                plt.axis('off')\n",
    "                plt.imshow(adv_image_visual) \n",
    "                plt.title(f\"Iteration {i + 1} Detection Results\")\n",
    "                plt.show()\n",
    "                \n",
    "            # After all iterations for a single image, save the results\n",
    "            save_results_to_csv(results, idx, SAVE_DIR, algorithm_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hard Clipping Gradient Based Method (adversarial pattern only generated in and around bounding boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuning parameters\n",
    "FACTOR = 0.4\n",
    "H = 10\n",
    "NUM_SAMPLES = 50\n",
    "NUM_ITERATIONS = 10\n",
    "EPS = 40000\n",
    "BUFFER_FACTOR =1\n",
    "algorithm_number = 3\n",
    "SAT = 10000\n",
    "\n",
    "SAVE_DIR = 'saved_images_3'\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# Main execution\n",
    "with detection_graph.as_default():\n",
    "    with tf.Session(graph=detection_graph) as sess:\n",
    "        image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "        boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "        scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "        classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "        num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "\n",
    "        for idx, image_path in enumerate(TEST_IMAGE_PATHS):\n",
    "            image_data = tf.read_file(image_path)\n",
    "            image_decoded = tf.image.decode_image(image_data)\n",
    "            image_np = sess.run(image_decoded)\n",
    "            original_shape = image_np.shape\n",
    "\n",
    "            adv_image = image_np.copy()\n",
    "            last_adv_image = np.copy(adv_image)  # To calculate the difference per iteration\n",
    "            results = []\n",
    "\n",
    "            # Iteration based on images\n",
    "            for i in range(NUM_ITERATIONS):\n",
    "                grad_approx = process_bounding_boxes(\n",
    "                    sess, adv_image, boxes, scores, classes, num_detections, image_tensor, 0.5, \n",
    "                    BUFFER_FACTOR, original_shape, FACTOR, NUM_SAMPLES, H\n",
    "                )\n",
    "\n",
    "                perturbed_adv_image = adv_image + np.clip(EPS * grad_approx, -SAT, SAT)\n",
    "\n",
    "                # Calculate the total and max perturbation before clipping\n",
    "                per_box_diff = perturbed_adv_image - last_adv_image\n",
    "                sum_diff = np.sum(np.abs(per_box_diff), axis=(0, 1, 2))\n",
    "                max_diff = np.max(np.abs(per_box_diff), axis=(0, 1, 2))\n",
    "\n",
    "                print(f\"Test Image {idx + 1}, Iteration {i + 1}:\")\n",
    "                print(f\"Sum_diff: {sum_diff}\")\n",
    "                print(f\"Max_diff: {max_diff}\")\n",
    "\n",
    "                # Initialize a flag to check if any scores are above the threshold\n",
    "                any_above_threshold = False\n",
    "\n",
    "                # Update the last_adv_image with the perturbed values before clipping\n",
    "                last_adv_image = perturbed_adv_image.copy()\n",
    "\n",
    "                # Apply clipping to keep pixel values valid for visualizing and further processing\n",
    "                adv_image = np.clip(perturbed_adv_image, 0, 255).astype(np.uint8)\n",
    "\n",
    "                # Save the adversarial image and get the image name\n",
    "                image_name = save_adversarial_image(adv_image, idx, i, SAVE_DIR, algorithm_number)\n",
    "\n",
    "                adv_image_expanded = np.expand_dims(adv_image, axis=0)\n",
    "                (iter_boxes, iter_scores, iter_classes, iter_num_detections) = sess.run(\n",
    "                    [boxes, scores, classes, num_detections],\n",
    "                    feed_dict={image_tensor: adv_image_expanded}\n",
    "                )\n",
    "                \n",
    "                # Save perturbation details per box\n",
    "                for j, score in enumerate(np.squeeze(iter_scores)):\n",
    "                    if score > score_threshold:\n",
    "                        any_above_threshold = True\n",
    "                        class_id = int(np.squeeze(iter_classes)[j])\n",
    "                        class_name = category_index[class_id]['name']\n",
    "                        box = np.squeeze(iter_boxes)[j].tolist()\n",
    "                        append_results(results, image_name, i, class_name, score, box, sum_diff, max_diff)\n",
    "                        print(f\"Detected class: {class_name}, Confidence Score: {score:.8f}\")\n",
    "\n",
    "                # If no scores were above threshold, record the max and sum diff\n",
    "                if not any_above_threshold:\n",
    "                    append_results(results, image_name, i, \"no_detection\", 0, [0, 0, 0, 0], sum_diff, max_diff)\n",
    "\n",
    "\n",
    "                # Visualization of the results\n",
    "                adv_image_visual = adv_image.copy()\n",
    "                vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "                    adv_image_visual, \n",
    "                    np.squeeze(iter_boxes),\n",
    "                    np.squeeze(iter_classes).astype(np.int32),\n",
    "                    np.squeeze(iter_scores),\n",
    "                    category_index,\n",
    "                    use_normalized_coordinates=True,\n",
    "                    line_thickness=6,\n",
    "                    min_score_thresh=0.5\n",
    "                )\n",
    "\n",
    "                # Save the visualized image with boxes\n",
    "                save_adversarial_image_with_boxes(adv_image_visual, idx, i, SAVE_DIR, algorithm_number)\n",
    "\n",
    "\n",
    "                plt.figure(figsize=IMAGE_SIZE)\n",
    "                plt.axis('off')\n",
    "                plt.imshow(adv_image_visual) \n",
    "                plt.title(f\"Iteration {i + 1} Detection Results\")\n",
    "                plt.show()\n",
    "                \n",
    "            # After all iterations for a single image, save the results\n",
    "            save_results_to_csv(results, idx, SAVE_DIR, algorithm_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projected Gradient Descent Method (adversarial pattern only generated in and around bounding boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_perturbation(perturbation, epsilon, p_norm='inf'):\n",
    "    \"\"\"\n",
    "    Project the perturbation onto an epsilon ball.\n",
    "    \"\"\"\n",
    "    if p_norm == 'inf':\n",
    "        return np.clip(perturbation, -epsilon, epsilon)\n",
    "    elif p_norm == 2:\n",
    "        norm = np.linalg.norm(perturbation)\n",
    "        if norm > epsilon:\n",
    "            return perturbation * (epsilon / norm)\n",
    "        return perturbation\n",
    "    else:\n",
    "        raise NotImplementedError(\"Only L-inf and L-2 norms are supported\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. l_inf Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuning parameters\n",
    "FACTOR = 0.4\n",
    "H = 10\n",
    "NUM_SAMPLES = 50\n",
    "NUM_ITERATIONS = 10\n",
    "EPS = 40000\n",
    "BUFFER_FACTOR =1\n",
    "algorithm_number = 5\n",
    "epsilon = 10000\n",
    "\n",
    "# Define the directory for saving images and results\n",
    "SAVE_DIR = 'saved_images_5'\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# Main execution\n",
    "with detection_graph.as_default():\n",
    "    with tf.Session(graph=detection_graph) as sess:\n",
    "        image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "        boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "        scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "        classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "        num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "\n",
    "        for idx, image_path in enumerate(TEST_IMAGE_PATHS):\n",
    "            image_data = tf.read_file(image_path)\n",
    "            image_decoded = tf.image.decode_image(image_data)\n",
    "            image_np = sess.run(image_decoded)\n",
    "            original_shape = image_np.shape\n",
    "\n",
    "            adv_image = image_np.copy()\n",
    "            last_adv_image = np.copy(adv_image)  # To calculate the difference per iteration\n",
    "            results = []\n",
    "\n",
    "            # Iteration based on images\n",
    "            for i in range(NUM_ITERATIONS):\n",
    "                grad_approx = process_bounding_boxes(\n",
    "                    sess, adv_image, boxes, scores, classes, num_detections, image_tensor, 0.5, \n",
    "                    BUFFER_FACTOR, original_shape, FACTOR, NUM_SAMPLES, H\n",
    "                )\n",
    "\n",
    "                # Project the perturbation onto the epsilon ball\n",
    "                perturbation = EPS * grad_approx\n",
    "                perturbation = project_perturbation(perturbation, epsilon)\n",
    "                # perturbation = project_perturbation(perturbation, epsilon, p_norm= 2)\n",
    "\n",
    "                # adv_image = adv_image.astype(np.float32)\n",
    "                perturbed_adv_image = adv_image + EPS * grad_approx \n",
    "\n",
    "                # Calculate the total and max perturbation before clipping\n",
    "                per_box_diff = perturbed_adv_image - last_adv_image\n",
    "                sum_diff = np.sum(np.abs(per_box_diff), axis=(0, 1, 2))\n",
    "                max_diff = np.max(np.abs(per_box_diff), axis=(0, 1, 2))\n",
    "\n",
    "                print(f\"Test Image {idx + 1}, Iteration {i + 1}:\")\n",
    "                print(f\"Sum_diff: {sum_diff}\")\n",
    "                print(f\"Max_diff: {max_diff}\")\n",
    "\n",
    "                # Initialize a flag to check if any scores are above the threshold\n",
    "                any_above_threshold = False\n",
    "\n",
    "                # Now apply clipping to keep pixel values valid for visualizing and further processing\n",
    "                adv_image = np.clip(perturbed_adv_image, 0, 255).astype(np.uint8)\n",
    "\n",
    "                # Update the last_adv_image with the perturbed values before clipping\n",
    "                last_adv_image = perturbed_adv_image.copy()\n",
    "\n",
    "                # Save the adversarial image and get the image name\n",
    "                image_name = save_adversarial_image(adv_image, idx, i, SAVE_DIR, algorithm_number)\n",
    "\n",
    "                adv_image_expanded = np.expand_dims(adv_image, axis=0)\n",
    "                (iter_boxes, iter_scores, iter_classes, iter_num_detections) = sess.run(\n",
    "                    [boxes, scores, classes, num_detections],\n",
    "                    feed_dict={image_tensor: adv_image_expanded}\n",
    "                )\n",
    "                \n",
    "                # Save perturbation details per box\n",
    "                for j, score in enumerate(np.squeeze(iter_scores)):\n",
    "                    if score > score_threshold:\n",
    "                        any_above_threshold = True\n",
    "                        class_id = int(np.squeeze(iter_classes)[j])\n",
    "                        class_name = category_index[class_id]['name']\n",
    "                        box = np.squeeze(iter_boxes)[j].tolist()\n",
    "                        append_results(results, image_name, i, class_name, score, box, sum_diff, max_diff)\n",
    "                        print(f\"Detected class: {class_name}, Confidence Score: {score:.8f}\")\n",
    "\n",
    "                # If no scores were above threshold, record the max and sum diff\n",
    "                if not any_above_threshold:\n",
    "                    append_results(results, image_name, i, \"no_detection\", 0, [0, 0, 0, 0], sum_diff, max_diff)\n",
    "\n",
    "\n",
    "                # Visualization of the results\n",
    "                adv_image_visual = adv_image.copy()\n",
    "                vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "                    adv_image_visual, \n",
    "                    np.squeeze(iter_boxes),\n",
    "                    np.squeeze(iter_classes).astype(np.int32),\n",
    "                    np.squeeze(iter_scores),\n",
    "                    category_index,\n",
    "                    use_normalized_coordinates=True,\n",
    "                    line_thickness=6,\n",
    "                    min_score_thresh=0.5\n",
    "                )\n",
    "\n",
    "                # Save the visualized image with boxes\n",
    "                save_adversarial_image_with_boxes(adv_image_visual, idx, i, SAVE_DIR, algorithm_number)\n",
    "\n",
    "                plt.figure(figsize=IMAGE_SIZE)\n",
    "                plt.axis('off')\n",
    "                plt.imshow(adv_image_visual) \n",
    "                plt.title(f\"Iteration {i + 1} Detection Results\")\n",
    "                plt.show()\n",
    "                \n",
    "            # After all iterations for a single image, save the results\n",
    "            save_results_to_csv(results, idx, SAVE_DIR, algorithm_number)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. l_2 Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuning parameters\n",
    "FACTOR = 0.4\n",
    "H = 10\n",
    "NUM_SAMPLES = 50\n",
    "NUM_ITERATIONS = 10\n",
    "EPS = 40000\n",
    "BUFFER_FACTOR =1\n",
    "algorithm_number = 6\n",
    "epsilon = 10000\n",
    "\n",
    "# Define the directory for saving images and results\n",
    "SAVE_DIR = 'saved_images_6'\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# Main execution\n",
    "with detection_graph.as_default():\n",
    "    with tf.Session(graph=detection_graph) as sess:\n",
    "        image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "        boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "        scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "        classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "        num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "\n",
    "        for idx, image_path in enumerate(TEST_IMAGE_PATHS):\n",
    "            image_data = tf.read_file(image_path)\n",
    "            image_decoded = tf.image.decode_image(image_data)\n",
    "            image_np = sess.run(image_decoded)\n",
    "            original_shape = image_np.shape\n",
    "\n",
    "            adv_image = image_np.copy()\n",
    "            last_adv_image = np.copy(adv_image)  # To calculate the difference per iteration\n",
    "            results = []\n",
    "\n",
    "            # Iteration based on images\n",
    "            for i in range(NUM_ITERATIONS):\n",
    "                grad_approx = process_bounding_boxes(\n",
    "                    sess, adv_image, boxes, scores, classes, num_detections, image_tensor, 0.5, \n",
    "                    BUFFER_FACTOR, original_shape, FACTOR, NUM_SAMPLES, H\n",
    "                )\n",
    "\n",
    "                # Project the perturbation onto the epsilon ball\n",
    "                perturbation = EPS * grad_approx\n",
    "                perturbation = project_perturbation(perturbation, epsilon, p_norm= 2)\n",
    "\n",
    "                # adv_image = adv_image.astype(np.float32)\n",
    "                perturbed_adv_image = adv_image + EPS * grad_approx \n",
    "\n",
    "                # Calculate the total and max perturbation before clipping\n",
    "                per_box_diff = perturbed_adv_image - last_adv_image\n",
    "                sum_diff = np.sum(np.abs(per_box_diff), axis=(0, 1, 2))\n",
    "                max_diff = np.max(np.abs(per_box_diff), axis=(0, 1, 2))\n",
    "\n",
    "                # Print out the desired information after the perturbation and before clipping\n",
    "                print(f\"Test Image {idx + 1}, Iteration {i + 1}:\")\n",
    "                print(f\"Sum_diff: {sum_diff}\")\n",
    "                print(f\"Max_diff: {max_diff}\")\n",
    "\n",
    "                # Initialize a flag to check if any scores are above the threshold\n",
    "                any_above_threshold = False\n",
    "\n",
    "                # Now apply clipping to keep pixel values valid for visualizing and further processing\n",
    "                adv_image = np.clip(perturbed_adv_image, 0, 255).astype(np.uint8)\n",
    "\n",
    "                # Update the last_adv_image with the perturbed values before clipping\n",
    "                last_adv_image = perturbed_adv_image.copy()\n",
    "\n",
    "                # Save the adversarial image and get the image name\n",
    "                image_name = save_adversarial_image(adv_image, idx, i, SAVE_DIR, algorithm_number)\n",
    "\n",
    "                adv_image_expanded = np.expand_dims(adv_image, axis=0)\n",
    "                (iter_boxes, iter_scores, iter_classes, iter_num_detections) = sess.run(\n",
    "                    [boxes, scores, classes, num_detections],\n",
    "                    feed_dict={image_tensor: adv_image_expanded}\n",
    "                )\n",
    "                \n",
    "                # Save perturbation details per box\n",
    "                for j, score in enumerate(np.squeeze(iter_scores)):\n",
    "                    if score > score_threshold:\n",
    "                        any_above_threshold = True\n",
    "                        class_id = int(np.squeeze(iter_classes)[j])\n",
    "                        class_name = category_index[class_id]['name']\n",
    "                        box = np.squeeze(iter_boxes)[j].tolist()\n",
    "                        append_results(results, image_name, i, class_name, score, box, sum_diff, max_diff)\n",
    "                        print(f\"Detected class: {class_name}, Confidence Score: {score:.8f}\")\n",
    "\n",
    "                # If no scores were above threshold, record the max and sum diff\n",
    "                if not any_above_threshold:\n",
    "                    append_results(results, image_name, i, \"no_detection\", 0, [0, 0, 0, 0], sum_diff, max_diff)\n",
    "\n",
    "\n",
    "                # Visualization of the results\n",
    "                adv_image_visual = adv_image.copy()\n",
    "                vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "                    adv_image_visual, \n",
    "                    np.squeeze(iter_boxes),\n",
    "                    np.squeeze(iter_classes).astype(np.int32),\n",
    "                    np.squeeze(iter_scores),\n",
    "                    category_index,\n",
    "                    use_normalized_coordinates=True,\n",
    "                    line_thickness=6,\n",
    "                    min_score_thresh=0.5\n",
    "                )\n",
    "\n",
    "                # Save the visualized image with boxes\n",
    "                save_adversarial_image_with_boxes(adv_image_visual, idx, i, SAVE_DIR, algorithm_number)\n",
    "\n",
    "                plt.figure(figsize=IMAGE_SIZE)\n",
    "                plt.axis('off')\n",
    "                plt.imshow(adv_image_visual) \n",
    "                plt.title(f\"Iteration {i + 1} Detection Results\")\n",
    "                plt.show()\n",
    "                \n",
    "            # After all iterations for a single image, save the results\n",
    "            save_results_to_csv(results, idx, SAVE_DIR, algorithm_number)\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
